---
title: "Theoretical Framework and Provable Guarantee for Weak-to-strong Generalization"
excerpt: "*Keywords: Weak supervision, data distillation, learning theory, Representation Learning*<br/><img src='/images/img3.png' width='450'>"
collection: publications
---

*Keywords: Weak supervision, data distillation, learning theory, Representation Learning*

**Advisor:** Prof. [Qi Lei](https://cecilialeiqi.github.io/), New York University

**Project Overview**

- Developing a theoretical framework for [Open AI's cutting-edge paper on weak-to-strong generalization](https://arxiv.org/abs/2312.09390). The focus is on quantifying the gains of the weak-supervised strong student model across various downstream tasks.
- Providing theoretical guarantees for future weak-supervised models (e.g., RLHF, learning under restricted data access), offering new insights into data distillation and enhancing understanding of weak supervision.

  
