---
title: "Theoretical Framework and Provable Guarantee for Weak-to-strong Generalization"
excerpt: "*Keywords: Weak supervision,  Random Numerical Linear Algebra, learning theory, Representation Learning*<br/><img src='/images/img3.png' width='450'>"
collection: publications
---

*Keywords: Weak supervision, learning theory, Random Numerical Linear Algebra, Representation Learning*

**Advisor:** Prof. [Qi Lei](https://cecilialeiqi.github.io/), New York University

**Project Overview**

- Developing a theoretical framework for [Open AI's cutting-edge paper on weak-to-strong generalization](https://arxiv.org/abs/2312.09390).  Studying
the weak-supervised strong student model’s quantifiable gain on various kinds of downstream tasks.
- Formalized model capacity using representation-based metrics for regression and classification case, exploring the
model capacities’ influence on the occurrence of weak-to-strong generalization.
-Deriving theoretical results, including sample complexity and empirical risk bounds, for data distributions across
varied settings.
-Paper in preparation.
